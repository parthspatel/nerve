<p align="center">
  <h1 align="center">âš¡ NERVE</h1>
  <p align="center"><strong>The Clinical Data Nervous System</strong></p>
  <p align="center">
    <em>Every signal. Every system. One truth.</em>
  </p>
</p>

<p align="center">
  <a href="#architecture"><img src="https://img.shields.io/badge/architecture-kubernetes--native-326CE5?style=flat-square&logo=kubernetes&logoColor=white" alt="Kubernetes Native"></a>
  <a href="#throughput"><img src="https://img.shields.io/badge/throughput-2M%2B_msg%2Fs-00C853?style=flat-square" alt="2M+ msg/s"></a>
  <a href="#license"><img src="https://img.shields.io/badge/license-Apache_2.0-blue?style=flat-square" alt="License"></a>
  <a href="#hl7"><img src="https://img.shields.io/badge/HL7-v2.x_%7C_FHIR_R4-FF6D00?style=flat-square" alt="HL7 v2.x | FHIR R4"></a>
  <a href="#stack"><img src="https://img.shields.io/badge/stack-100%25_OSS-black?style=flat-square" alt="100% Open Source"></a>
</p>

-----

## What is Nerve?

Your hospitals generate millions of clinical signals every day â€” admissions, labs, orders, notes, scans, charges â€” scattered across Epic, OnBase, PACS, and dozens of other systems that were never designed to talk to each other. By the time your RCM team pieces together the full picture, youâ€™ve already lost revenue, missed denials, and coded from incomplete data.

**Nerve is the real-time clinical data fabric** that intercepts every HL7 message, every FHIR resource, every scanned document, and every radiology study the instant itâ€™s created â€” then unifies it into a single, queryable clinical truth across every facility in your system. Not in hours. Not in batches. In *milliseconds*.

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                          N E R V E                               â”‚
  â”‚                                                                  â”‚
  â”‚  Epic â”€â”€â”€â”€â”€â”                                                     â”‚
  â”‚  OnBase â”€â”€â”€â”¤â”€â”€ Go MLLP â”€â”€â–¶ Kafka â”€â”€â–¶ Flink â”€â”€â”¬â”€â”€â–¶ Delta Lake   â”‚
  â”‚  PACS â”€â”€â”€â”€â”€â”¤   Pods        Strimzi   + HAPI   â”œâ”€â”€â–¶ PostgreSQL   â”‚
  â”‚  Others â”€â”€â”€â”˜                                   â””â”€â”€â–¶ OpenSearch   â”‚
  â”‚                                                        â”‚         â”‚
  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â–¼         â”‚
  â”‚     â”‚  SQLMesh + Apache Hop            â”‚          Trino SQL      â”‚
  â”‚     â”‚  Visual clinical transforms      â”‚          Analytics      â”‚
  â”‚     â”‚  Git-backed â€¢ Version-controlled â”‚                         â”‚
  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
  â”‚                                                                  â”‚
  â”‚  MPI: HAPI FHIR MDM + Splink (200M+ record proven)             â”‚
  â”‚  Deploy: ArgoCD â”‚ Scale: KEDA â”‚ Mesh: Linkerd â”‚ Secrets: Vault  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

-----

## Why Nerve?

|Problem                                            |Nerveâ€™s Answer                                              |
|---------------------------------------------------|------------------------------------------------------------|
|Legacy integration engines canâ€™t horizontally scale|Go MLLP pods scale to **2M+ msg/s** on K8s via KEDA         |
|Only engineers can map HL7 fields across systems   |**Visual dbt-style studio** for clinicians and coders       |
|Patient records fragmented across facilities       |**Hybrid MPI** with real-time + batch probabilistic matching|
|No single source of truth for RCM analytics        |**Delta Lake medallion** â€” Bronze â†’ Silver â†’ Gold           |
|Vendor lock-in and per-message pricing             |**100% open source**, Apache 2.0 licensed                   |

-----

## Key Capabilities

### âš¡ 2M+ Messages, Sub-Second ACK

Nerveâ€™s Go-based MLLP ingestion layer horizontally scales across Kubernetes pods to absorb massive HL7 pulse loads. Apache Flink parses every ADT, ORM, ORU, DFT, and MDM in real-time with the HAPI library. Kafka provides the durable backbone. ACKs fire in under 5 milliseconds. The sending system never waits.

### ðŸŽ¨ Clinician-Designed Mappings

Every hospital speaks its own dialect of HL7. Nerve gives your clinical analysts and coders a visual transformation studio â€” drag-and-drop field mapping, point-and-click code translation, version-controlled through Git. When Hospital A sends diagnosis as a local code and Hospital B sends ICD-10-CM, your clinical team defines the unification rules themselves. No tickets. No six-week dev cycles.

### ðŸ”— One Patient, One Record, Every Facility

Nerveâ€™s hybrid Master Patient Index combines real-time deterministic matching on every incoming ADT with batch probabilistic deduplication using the Fellegi-Sunter model â€” the same approach the U.S. Defense Health Agency used to deduplicate 200M+ records.

### ðŸ—ï¸ Medallion Lakehouse for Clinical Data

|Layer     |What Lives Here                                                                                                                                         |
|----------|--------------------------------------------------------------------------------------------------------------------------------------------------------|
|**Bronze**|Raw wire format. Immutable. Every HL7 message preserved exactly as received. HIPAA audit trail with time travel.                                        |
|**Silver**|Parsed, validated, deduplicated. PID â†’ demographics, OBX â†’ observations. Local codes â†’ ICD-10, SNOMED CT. Tagged with `source_system` and `facility_id`.|
|**Gold**  |Unified star schema. `DIM_PATIENT` Ã— `FACT_ENCOUNTER` Ã— `FACT_CLAIM`. Denial rates, charge capture, A/R aging. Query with Trino in seconds.             |

-----

## Supported Sources

|Source            |Protocol        |What Nerve Captures                                      |
|------------------|----------------|---------------------------------------------------------|
|**Epic**          |MLLP + FHIR R4  |ADT, orders, results, charges, notes, 750+ FHIR resources|
|**OnBase**        |REST / Unity API|Scanned documents, faxes, EOBs, consent forms            |
|**PACS**          |DICOM / DICOMweb|Radiology metadata, study context, modality worklists    |
|**Any HL7 sender**|MLLP/TCP        |Full v2.x support, all message types, all versions       |

-----

## Architecture

Nerve follows a five-layer architecture â€” **Ingestion â†’ Streaming â†’ Processing â†’ Storage â†’ Serving** â€” each independently scalable on Kubernetes and connected through Kafka as the central nervous system.

### Data Flow

```
Epic/Source EHR â”€â”€MLLP/TCPâ”€â”€â–¶ [Go MLLP Pods] â”€â”€produceâ”€â”€â–¶ [Kafka: hl7.raw.ingest]
                                    â”‚ ACK                          â”‚
                                    â–¼                              â–¼
                              Sub-second ACK             [Flink: Parse + Validate]
                              back to source              HAPI HL7v2 library
                                                                   â”‚
                                                                   â–¼
                                                      [Kafka: hl7.parsed.{type}]
                                                           â”‚    â”‚    â”‚
                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                            â–¼                   â–¼                   â–¼
                                     [Delta Lake]        [PostgreSQL]        [OpenSearch]
                                     Bronzeâ†’Silverâ†’Gold   Operational DB     Clinical Search
                                            â”‚
                                            â–¼
                                [SQLMesh / Hop Transforms]
                                 dbt-style, Git-backed
                                            â”‚
                                            â–¼
                                     [Trino Queries]
                                     Gold Layer Analytics
```

### Secondary Source Flows

```
OnBase â”€â”€REST APIâ”€â”€â–¶ [Document Connector] â”€â”€â–¶ Kafka â”€â”€â–¶ Flink â”€â”€â–¶ Delta / OpenSearch
PACS   â”€â”€DICOMâ”€â”€â”€â”€â–¶ [Orthanc Proxy]       â”€â”€â–¶ Kafka â”€â”€â–¶ Flink â”€â”€â–¶ Delta / OpenSearch
Epic   â”€â”€FHIR R4â”€â”€â–¶ [FHIR Poller]         â”€â”€â–¶ Kafka â”€â”€â–¶ Flink â”€â”€â–¶ Delta / PostgreSQL
```

### Kafka Topic Strategy

|Topic           |Key Strategy               |Purpose                               |
|----------------|---------------------------|--------------------------------------|
|`hl7.raw.ingest`|`facility_id + sending_app`|Raw MLLP messages, per-source ordering|
|`hl7.parsed.adt`|`patient_mrn_hash`         |Parsed ADT, patient-level ordering    |
|`hl7.parsed.orm`|`patient_mrn_hash`         |Parsed orders                         |
|`hl7.parsed.oru`|`patient_mrn_hash`         |Parsed results                        |
|`hl7.parsed.dft`|`encounter_id`             |Financial transactions                |
|`hl7.parsed.mdm`|`patient_mrn_hash`         |Document management                   |
|`hl7.dlq`       |Original key               |Dead letter queue                     |

-----

## Tech Stack

Every component is open source. No vendor lock-in. No per-message pricing. No â€œcall us for enterprise.â€

|Layer              |Component                          |Role                                                  |License          |
|-------------------|-----------------------------------|------------------------------------------------------|-----------------|
|**Ingestion**      |Custom Go MLLP                     |HL7 v2.x TCP listener, horizontal pod scaling         |Apache 2.0       |
|**Streaming**      |Apache Kafka (Strimzi)             |Durable message backbone, KRaft mode                  |Apache 2.0       |
|**Processing**     |Apache Flink + HAPI HL7v2          |Real-time parse, validate, route, enrich              |Apache 2.0       |
|**Batch ETL**      |Apache Spark                       |Delta Lake writes, medallion pipeline                 |Apache 2.0       |
|**Transforms**     |SQLMesh                            |dbt-style SQL transforms with version control         |Apache 2.0       |
|**Visual ETL**     |Apache Hop                         |Drag-and-drop mapping UI for clinical users           |Apache 2.0       |
|**Lakehouse**      |Delta Lake on MinIO                |Bronze/Silver/Gold medallion, time travel, audit      |Apache 2.0 / AGPL|
|**Operational DB** |PostgreSQL (CloudNativePG)         |Transactional store, HA with automated failover       |Apache 2.0       |
|**Search**         |OpenSearch                         |Clinical document indexing, NLP entity extraction     |Apache 2.0       |
|**MPI**            |HAPI FHIR MDM + Splink             |Real-time deterministic + batch probabilistic matching|Apache 2.0 / MIT |
|**DICOM**          |Orthanc                            |DICOM proxy, DICOMweb, metadata extraction            |GPLv3            |
|**Query**          |Trino                              |Interactive SQL on Delta Lake Gold layer              |Apache 2.0       |
|**Schema Registry**|Apicurio Registry                  |Kafka schema management (Avro, JSON Schema)           |Apache 2.0       |
|**GitOps**         |ArgoCD + Argo Rollouts             |Declarative deployment, canary releases               |Apache 2.0       |
|**Autoscaling**    |KEDA                               |Event-driven scaling on Kafka consumer lag            |Apache 2.0       |
|**Service Mesh**   |Linkerd                            |mTLS pod-to-pod, HIPAA encryption in transit          |Apache 2.0       |
|**Secrets**        |HashiCorp Vault                    |Dynamic credentials, secret rotation, audit           |MPL 2.0          |
|**Observability**  |Prometheus + Grafana + Loki + Tempo|Metrics, logs, traces, dashboards                     |Apache 2.0 / AGPL|

-----

## Kubernetes Deployment

### Namespace Topology

```
platform-kafka             # Strimzi Kafka cluster (3+ brokers)
platform-flink             # Flink JobManager + TaskManagers
platform-storage           # MinIO, PostgreSQL (CloudNativePG), OpenSearch
platform-observability     # Prometheus, Grafana, Loki, Tempo, OTel Collector
platform-security          # Vault, cert-manager
clinical-ingestion         # MLLP listeners, FHIR pollers, OnBase/DICOM connectors
clinical-processing        # Flink jobs, Spark jobs, SQLMesh runners
clinical-serving           # Trino, HAPI FHIR (MPI), Hop UI, mapping UI
clinical-transforms        # Apache Hop server, transformation runners
```

### Autoscaling Strategy

|Component         |Scaler            |Signal              |Min â†’ Max Pods     |
|------------------|------------------|--------------------|-------------------|
|MLLP Listeners    |KEDA / Prometheus |Message receive rate|2 â†’ 16             |
|Flink TaskManagers|Flink Autoscaler  |Backpressure + lag  |4 â†’ 32             |
|Kafka Consumers   |KEDA / Kafka      |Consumer group lag  |2 â†’ partition count|
|Trino Workers     |KEDA / Prometheus |Query queue depth   |2 â†’ 20             |
|Spark Executors   |Dynamic Allocation|Pending tasks       |2 â†’ 32             |

### HIPAA Security Baseline

- **Encryption in transit**: Linkerd mTLS on all pod-to-pod traffic (zero-config)
- **Encryption at rest**: Encrypted StorageClasses for all PVs containing PHI
- **Secrets**: Vault with dynamic credential rotation, per-secret ACL policies
- **Network**: Default-deny NetworkPolicies, explicit allowlists per namespace
- **Pod Security**: `restricted` PSS profile â€” non-root, read-only filesystem
- **Policy**: OPA Gatekeeper / Kyverno for admission control
- **Scanning**: Trivy image vulnerability scanning in CI/CD
- **Runtime**: Falco intrusion detection
- **Audit**: K8s API audit logs â†’ Loki with immutable storage (6-year retention)

-----

## Transformation Studio

Nerveâ€™s transformation layer is designed for **non-technical clinical users** â€” coders, RCM analysts, and clinicians â€” to define and version data mappings without engineering support.

### How It Works

```
Clinical User â”€â”€(visual UI)â”€â”€â–¶ Mapping Definition (YAML/SQL)
                                        â”‚
                                        â–¼
                               Git Repository (PR)
                                        â”‚
                                   Peer Review
                                        â”‚
                                        â–¼
                               CI/CD validates + tests
                                        â”‚
                                        â–¼
                               ArgoCD deploys to K8s
                                        â”‚
                                        â–¼
                          SQLMesh plan/apply or Flink job update
```

**Three composable layers:**

1. **SQLMesh** â€” SQL-based transformations on Delta Lake. ~9x faster than dbt through incremental state tracking. Virtual environments for safe development. Automatic breaking-change detection on schema evolution.
1. **Apache Hop** â€” Visual drag-and-drop pipeline designer with 400+ plugins. Git-native project structure. Executes on Flink or Spark via Apache Beam. The interface clinicians actually use.
1. **Declarative YAML mappings** â€” Field-level sourceâ†’target definitions (`PID.5.1 â†’ patient.lastName`), code system translations (local â†’ ICD-10/SNOMED CT), validation rules. Git-backed, executed by Flink operators.

-----

## Master Patient Index

Nerveâ€™s hybrid MPI combines two strategies for comprehensive patient matching:

**Real-time (HAPI FHIR MDM):**

- Deterministic matching on every incoming ADT message
- Golden Record management with FHIR Patient.link references
- Automatic MATCH / POSSIBLE_MATCH / NO_MATCH classification
- Manual review workflows for ambiguous cases
- Configurable rules: Soundex, Cologne phonetic, Jaro-Winkler similarity

**Batch (Splink):**

- Fellegi-Sunter probabilistic model with unsupervised EM learning
- No training data required
- Proven at 200M+ records (US Defense Health Agency)
- Interactive visualizations for match quality review
- Results feed back into HAPI MDM via `$mdm-submit`

-----

## Data Isolation Model

Nerve uses **system-level data tagging** rather than namespace isolation. Every record at every layer carries:

```json
{
  "source_system": "epic-phoenix",
  "facility_id": "FAC-001",
  "empi_id": "GOLD-12345",
  "ingestion_ts": "2026-02-05T12:00:00Z"
}
```

- **Within a system**: Patient records are unified across facilities via MPI
- **Across systems**: Data isolation enforced at the data level â€” every entry tagged with `source_system`
- **PostgreSQL**: Composite unique constraints (`source_system, facility_id, mrn`), Row-Level Security policies
- **Delta Lake**: Partitioned by `source_system/facility_id` at Silver/Gold layers
- **OpenSearch**: Separate indices per document type with system-level field filtering

-----

## Quick Start

> **Prerequisites**: Kubernetes 1.28+, Helm 3.x, `kubectl` configured

```bash
# 1. Install platform operators
helm repo add strimzi https://strimzi.io/charts
helm repo add flink-operator https://downloads.apache.org/flink/flink-kubernetes-operator-1.13.0/
helm repo add minio https://operator.min.io
helm repo add cnpg https://cloudnative-pg.github.io/charts
helm repo add argo https://argoproj.github.io/argo-helm

helm install strimzi strimzi/strimzi-kafka-operator -n platform-kafka --create-namespace
helm install flink-operator flink-operator/flink-kubernetes-operator -n platform-flink --create-namespace
helm install minio-operator minio/operator -n platform-storage --create-namespace
helm install cnpg cnpg/cloudnative-pg -n platform-storage
helm install argocd argo/argo-cd -n argocd --create-namespace

# 2. Install KEDA for autoscaling
helm repo add kedacore https://kedacore.github.io/charts
helm install keda kedacore/keda -n keda --create-namespace

# 3. Install Linkerd for mTLS
curl -sL https://run.linkerd.io/install | sh
linkerd install --crds | kubectl apply -f -
linkerd install | kubectl apply -f -

# 4. Deploy Nerve via ArgoCD App-of-Apps
kubectl apply -f deploy/argocd/nerve-app-of-apps.yaml
```

See [`deploy/`](deploy/) for complete Helm values, Kafka CRDs, Flink job specs, and environment-specific overlays.

-----

## Project Structure

```
nerve/
â”œâ”€â”€ deploy/                          # Kubernetes manifests & Helm values
â”‚   â”œâ”€â”€ argocd/                      # ArgoCD Application definitions
â”‚   â”œâ”€â”€ kafka/                       # Strimzi Kafka CRDs, topic configs
â”‚   â”œâ”€â”€ flink/                       # Flink job specs, autoscaler configs
â”‚   â”œâ”€â”€ storage/                     # MinIO tenants, CloudNativePG clusters
â”‚   â”œâ”€â”€ observability/               # Prometheus rules, Grafana dashboards
â”‚   â””â”€â”€ environments/                # dev / staging / prod overlays
â”œâ”€â”€ ingestion/                       # Go MLLP listener service
â”‚   â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ go.mod
â”œâ”€â”€ connectors/                      # Source system adapters
â”‚   â”œâ”€â”€ epic-fhir-poller/            # FHIR R4 bulk + polling
â”‚   â”œâ”€â”€ onbase-adapter/              # Hyland OnBase REST/Unity
â”‚   â”œâ”€â”€ dicom-proxy/                 # Orthanc config + metadata extractor
â”‚   â””â”€â”€ generic-mllp/                # Fallback HL7 v2.x connector
â”œâ”€â”€ processing/                      # Flink jobs (Java/Kotlin)
â”‚   â”œâ”€â”€ hl7-parser/                  # HAPI-based parse + validate + route
â”‚   â”œâ”€â”€ enrichment/                  # Code normalization, MPI lookup
â”‚   â””â”€â”€ document-processor/          # Clinical note + PDF extraction
â”œâ”€â”€ transforms/                      # Clinical transformation layer
â”‚   â”œâ”€â”€ sqlmesh/                     # SQLMesh models (Bronzeâ†’Silverâ†’Gold)
â”‚   â”œâ”€â”€ hop-pipelines/               # Apache Hop visual pipelines
â”‚   â”œâ”€â”€ mappings/                    # YAML field mapping definitions
â”‚   â””â”€â”€ code-tables/                 # Localâ†’standard code translations
â”œâ”€â”€ mpi/                             # Master Patient Index
â”‚   â”œâ”€â”€ hapi-fhir-config/            # HAPI FHIR MDM rules + deployment
â”‚   â””â”€â”€ splink-jobs/                 # Batch probabilistic matching
â”œâ”€â”€ serving/                         # Query & API layer
â”‚   â”œâ”€â”€ trino/                       # Trino catalog + config
â”‚   â””â”€â”€ api/                         # REST API for downstream systems
â”œâ”€â”€ ui/                              # Clinical user interfaces
â”‚   â”œâ”€â”€ mapping-studio/              # React app for visual field mapping
â”‚   â””â”€â”€ mpi-review/                  # Match review + adjudication UI
â”œâ”€â”€ schemas/                         # Apicurio registry schemas
â”‚   â”œâ”€â”€ avro/
â”‚   â””â”€â”€ json-schema/
â”œâ”€â”€ tests/                           # Integration + E2E tests
â”‚   â”œâ”€â”€ hl7-fixtures/                # Sample HL7 v2.x messages
â”‚   â”œâ”€â”€ fhir-fixtures/               # Sample FHIR R4 bundles
â”‚   â””â”€â”€ integration/                 # Pipeline integration tests
â””â”€â”€ docs/                            # Architecture docs, runbooks
    â”œâ”€â”€ architecture.md
    â”œâ”€â”€ onboarding-new-facility.md
    â””â”€â”€ runbooks/
```

-----

## Roadmap

- [ ] Go MLLP listener with Kafka producer + KEDA scaling
- [ ] Strimzi Kafka cluster with HL7 topic topology
- [ ] Flink HL7 parser with HAPI v2.x integration
- [ ] Delta Lake medallion pipeline (Bronze â†’ Silver)
- [ ] HAPI FHIR MDM for real-time patient matching
- [ ] SQLMesh Gold layer transformations
- [ ] Apache Hop visual pipeline integration
- [ ] Clinical mapping studio UI
- [ ] Epic FHIR R4 poller with Bulk Data Export
- [ ] OnBase document connector
- [ ] Orthanc DICOM proxy + metadata extraction
- [ ] Splink batch MPI deduplication
- [ ] OpenSearch clinical document indexing
- [ ] Trino interactive query layer
- [ ] Argo Rollouts canary deployment pipeline
- [ ] HIPAA compliance validation suite

-----

<p align="center">
  <strong>Nerve</strong> â€” because your revenue cycle shouldn't wait for your integration team.
</p>
